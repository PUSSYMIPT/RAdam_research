{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-04T15:07:07.441147Z",
     "start_time": "2019-12-04T15:07:02.360419Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle as p\n",
    "import numpy as np\n",
    "from plotly import graph_objects as go\n",
    "import os\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from tqdm.notebook import tqdm  # last tqdm update\n",
    "from scipy.stats import shapiro\n",
    "from statsmodels.sandbox.stats.multicomp import multipletests "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-04T15:07:08.243507Z",
     "start_time": "2019-12-04T15:07:07.644885Z"
    }
   },
   "outputs": [],
   "source": [
    "first_ten = []\n",
    "for file in os.listdir('./Adam'):\n",
    "    with open('./Adam/' + file, 'rb') as inp:\n",
    "        try:\n",
    "            first_ten.append(p.load(inp)[0][:10])\n",
    "        except:\n",
    "            pass\n",
    "first_ten = np.array(first_ten)\n",
    "first_ten.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Распределение градиентов\n",
    "\n",
    "## Данные\n",
    "\n",
    "Для первых ста итераций обучения были получены значения градиентов для весов между десятью нейронами на последнем слое и\n",
    "Предпоследним скрытым слоем с 512 нейронами.\n",
    "\n",
    "## Первый взгляд\n",
    "\n",
    "Давайте посмотрим на все градиенты для каждого нейрона за все итерации. Такая апроксимация не слишком математична, так как для каждого веса распределение свое, однако такая интерперетация более наглядна. Полученная величина -- смесь нормальных распределений. Оценим эту смесь через `GaussianMixture` и построим гистограммы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-04T15:07:33.221385Z",
     "start_time": "2019-12-04T15:07:24.030444Z"
    }
   },
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "\n",
    "\n",
    "\n",
    "data = []\n",
    "all_grad = []\n",
    "mixt_est = []\n",
    "\n",
    "\n",
    "for param in range(10):\n",
    "    param_grad = first_ten[:, param, :].reshape(-1)\n",
    "    all_grad.append(param_grad)\n",
    "\n",
    "\n",
    "\n",
    "models = []\n",
    "\n",
    "for it in range(10):\n",
    "    data.append(go.Histogram({\n",
    "        'x': all_grad[it],\n",
    "        'opacity': 0.7,\n",
    "        'histnorm': 'probability density',\n",
    "        'name': 'param: {} all weights'.format(it+1)\n",
    "    }))\n",
    "    cur_model = GaussianMixture(5)\n",
    "    cur_model.fit(all_grad[it].reshape(-1, 1))\n",
    "    x = np.linspace(np.min(all_grad[it]), np.max(all_grad[it]), 200).reshape(-1, 1)\n",
    "    y = cur_model.score_samples(x).reshape(-1)\n",
    "    if it == 0:\n",
    "        mixt_est.append(go.Scatter({\n",
    "            'x': x.reshape(-1),\n",
    "            'y': np.exp(y),\n",
    "            'marker': {\n",
    "                'color': 'red'\n",
    "            },\n",
    "        \n",
    "            'name': 'Gaussian mixture estimator'\n",
    "        }))\n",
    "        continue\n",
    "        \n",
    "    mixt_est.append(go.Scatter({\n",
    "        'x': x.reshape(-1),\n",
    "        'y': np.exp(y),\n",
    "        'marker': {\n",
    "            'color': 'red'\n",
    "        },\n",
    "        \n",
    "        'showlegend': False\n",
    "    }))\n",
    "    \n",
    "\n",
    "fig = make_subplots(cols=4, rows=3)\n",
    "\n",
    "for idx, trace in enumerate(data):\n",
    "    fig.add_trace(mixt_est[idx], col=idx//3 + 1, row=idx%3+1)\n",
    "    fig.add_trace(trace, col=idx//3 + 1, row=idx%3+1)\n",
    "    \n",
    "    \n",
    "layout = go.Layout({\n",
    "    'title': 'Distribution of gradients',\n",
    "    'width': 1000,\n",
    "    'height': 800,\n",
    "    'template': 'plotly_white',\n",
    "    #'legend_orientation': 'h',\n",
    "    'legend': {\n",
    "        'x': 0.8,\n",
    "        'y': 0.4\n",
    "    }\n",
    "})\n",
    "fig.update_layout(layout)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вывод\n",
    "\n",
    "Как видим данные вполне неплохо подходят под данное распределение, а значит мы можем продолжить нашу проверку на нормальность градиентов каждого веса.\n",
    "\n",
    "## Критерий согласия Шапиро-Уилка\n",
    "\n",
    "Для каждого веса для каждого нейрона проверим гипотезу $H_0: \\text{\"Градиенты на данном весе распределены нормально\"} $ против альтернативы $H_1: \\text{\"Иначе\"} $. Для этого воспользуемся критерием согласия Шапиро-Уилка."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-04T14:45:18.134538Z",
     "start_time": "2019-12-04T14:45:17.743643Z"
    }
   },
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "\n",
    "p_values = []\n",
    "for param in tqdm(range(10)):\n",
    "    p_values_param = []\n",
    "    for weight in range(512):\n",
    "        p_value = shapiro(first_ten[:, param, weight])[1]\n",
    "        p_values_param.append(p_value)\n",
    "    p_values.append(p_values_param)\n",
    "\n",
    "p_values = np.array(p_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, число не отвергнутых гипотез и отвергнутых гипотез можем видеть в выводе следующе ячейки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-04T14:45:28.351045Z",
     "start_time": "2019-12-04T14:45:28.339957Z"
    }
   },
   "outputs": [],
   "source": [
    "accepted = p_values[p_values > alpha]\n",
    "rejected = p_values[p_values <= alpha]\n",
    "len(accepted), len(rejected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так же посмотрим на каждый нейрон и веса, принадлежащие конкретному нейрону."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-04T14:16:08.977282Z",
     "start_time": "2019-12-04T14:16:08.966566Z"
    }
   },
   "outputs": [],
   "source": [
    "for idx, param_p in enumerate(p_values):\n",
    "    accepted = len(param_p[param_p > alpha])\n",
    "    rejected = len(param_p[param_p <= alpha])\n",
    "    print('For parameter {} Shapiro-Wilk test results are:\\n accepted {}; rejected {}; percentage accepted {:.2f}'.format(\n",
    "    idx+1, accepted, rejected, accepted/len(param_p)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Множественная проверка гипотез\n",
    "\n",
    "Воспользуемся поправками Холма и Бенджамини-Хохберга. Посмотрим какая из них даст более мощный результат и воспользуемся такой.\n",
    "\n",
    "Будем проверять гипотезу $H_0: \\text{\"В целом градиенты распределены нормально\"} $ против $ H_1: \\text{\"Иначе\"} $\n",
    "\n",
    "### Метод Холма"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-04T14:53:44.925138Z",
     "start_time": "2019-12-04T14:53:43.920859Z"
    }
   },
   "outputs": [],
   "source": [
    "reject, p_corrected, a1, a2 = multipletests(p_values.reshape(-1), \n",
    "                                            alpha = 0.05, \n",
    "                                            method = 'holm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-04T14:54:48.244730Z",
     "start_time": "2019-12-04T14:54:48.236019Z"
    }
   },
   "outputs": [],
   "source": [
    "reject.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Метод Бенджамини-Хохберга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-04T14:55:35.033938Z",
     "start_time": "2019-12-04T14:55:35.026908Z"
    }
   },
   "outputs": [],
   "source": [
    "reject, p_corrected, a1, a2 = multipletests(p_values.reshape(-1), \n",
    "                                            alpha = 0.05, \n",
    "                                            method = 'fdr_bh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-04T14:55:40.323553Z",
     "start_time": "2019-12-04T14:55:40.315869Z"
    }
   },
   "outputs": [],
   "source": [
    "reject.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод \n",
    "С помощью метода Бенджамини-Хохберга удалось отвергнуть больше гипотез, а значит он является более мощным в данном случае."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
